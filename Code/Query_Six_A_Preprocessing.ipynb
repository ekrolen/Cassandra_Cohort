{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b10d9b4",
   "metadata": {},
   "source": [
    "# Query Six A Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9695665",
   "metadata": {},
   "source": [
    "#### Are there any listings that a reviewer has reviewed more than thrice that is also available in the same month as was reviewed by them previously? (check against all the months that the previous reviews were posted on, if any match then it qualifies)\n",
    "\n",
    "#### Goal: Clean the data files in prepartion for loading into Cassandra on Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4c9e2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6e74a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading the data\n",
    "pdx_reviews = pd.read_csv('PDX_reviews.csv')\n",
    "la_reviews = pd.read_csv('la_reviews.csv')\n",
    "sd_reviews = pd.read_csv('sd_reviews.csv')\n",
    "salem_reviews = pd.read_csv('salem_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "0b131ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping only the columns we need (listing_id, id, date, reviewer_id, reviewer_name (for 6b))\n",
    "pdx_select = pdx_reviews[[\"listing_id\", \"id\",\"date\",\"reviewer_id\", \"reviewer_name\"]]\n",
    "la_select = la_reviews[[\"listing_id\", \"id\",\"date\",\"reviewer_id\", \"reviewer_name\"]]\n",
    "sd_select = sd_reviews[[\"listing_id\", \"id\",\"date\",\"reviewer_id\", \"reviewer_name\"]]\n",
    "salem_select = salem_reviews[[\"listing_id\", \"id\",\"date\",\"reviewer_id\", \"reviewer_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a480ddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concat worked correctly. New len: 2573162\n"
     ]
    }
   ],
   "source": [
    "#Combining all reviews for all cities\n",
    "df_list = [pdx_select, la_select, sd_select, salem_select]\n",
    "all_reviews = pd.concat(df_list)\n",
    "\n",
    "#Testing concat\n",
    "indiv_lengths = len(pdx_select) + len(la_select) + len(sd_select) + len(salem_select)\n",
    "if len(all_reviews) == indiv_lengths:\n",
    "    print(\"Concat worked correctly. New len: \"+str(len(all_reviews)))\n",
    "else:\n",
    "    print(\"Concat did not merge right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "08a215aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting date to datetime and adding month column\n",
    "all_reviews['date'] = pd.to_datetime(all_reviews['date'])\n",
    "all_reviews['review_month'] = all_reviews['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "111abeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>review_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12899</td>\n",
       "      <td>24767</td>\n",
       "      <td>69327</td>\n",
       "      <td>Stuart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12899</td>\n",
       "      <td>29230</td>\n",
       "      <td>72846</td>\n",
       "      <td>John</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12899</td>\n",
       "      <td>29806</td>\n",
       "      <td>84196</td>\n",
       "      <td>Lois</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12899</td>\n",
       "      <td>32572</td>\n",
       "      <td>89114</td>\n",
       "      <td>Troy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12899</td>\n",
       "      <td>32862</td>\n",
       "      <td>100318</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14881</th>\n",
       "      <td>806288048006012567</td>\n",
       "      <td>840008042809282936</td>\n",
       "      <td>219002106</td>\n",
       "      <td>Cheryl</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14882</th>\n",
       "      <td>806288048006012567</td>\n",
       "      <td>840728285056856719</td>\n",
       "      <td>52054229</td>\n",
       "      <td>Sarah</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14883</th>\n",
       "      <td>808194120211324072</td>\n",
       "      <td>822551660654988407</td>\n",
       "      <td>82164517</td>\n",
       "      <td>Jody</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14884</th>\n",
       "      <td>810859442087199945</td>\n",
       "      <td>818218402306004794</td>\n",
       "      <td>415177874</td>\n",
       "      <td>Alanmichael</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14885</th>\n",
       "      <td>850643329762179893</td>\n",
       "      <td>852973957827370635</td>\n",
       "      <td>114069411</td>\n",
       "      <td>Adam</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2573162 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               listing_id                  id  reviewer_id reviewer_name  \\\n",
       "0                   12899               24767        69327        Stuart   \n",
       "1                   12899               29230        72846          John   \n",
       "2                   12899               29806        84196          Lois   \n",
       "3                   12899               32572        89114          Troy   \n",
       "4                   12899               32862       100318         Cathy   \n",
       "...                   ...                 ...          ...           ...   \n",
       "14881  806288048006012567  840008042809282936    219002106        Cheryl   \n",
       "14882  806288048006012567  840728285056856719     52054229         Sarah   \n",
       "14883  808194120211324072  822551660654988407     82164517          Jody   \n",
       "14884  810859442087199945  818218402306004794    415177874   Alanmichael   \n",
       "14885  850643329762179893  852973957827370635    114069411          Adam   \n",
       "\n",
       "       review_month  \n",
       "0                 1  \n",
       "1                 3  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 4  \n",
       "...             ...  \n",
       "14881             3  \n",
       "14882             3  \n",
       "14883             2  \n",
       "14884             2  \n",
       "14885             3  \n",
       "\n",
       "[2573162 rows x 5 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing date column\n",
    "final_reviews = all_reviews.loc[:, all_reviews.columns!='date']\n",
    "final_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d1d0650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#Saving the final reviews table for the creation of the dummy availability table\\nfinal_reviews.to_csv(\"q6_comb_reviews.csv\")'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#Saving the final reviews table for the creation of the dummy availability table\n",
    "final_reviews.to_csv(\"q6_comb_reviews.csv\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b374655",
   "metadata": {},
   "source": [
    "### Cleaning the Availability Table\n",
    "Steps:\n",
    "    1. Load table\n",
    "    2. Change date to a datetime col\n",
    "    3. Create a avail_month col\n",
    "    4. Remove all columns which aren't listing_id, avail_month, and true_availability\n",
    "    5. Combine the avail_month rows into a single col per listing id with comma separated values\n",
    "    6. Remove the true_availability = False column\n",
    "    7. Save dataset'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "8f3df3a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 168. MiB for an array with shape (21966856,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [213]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loading the availability table\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avail_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_avail_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m avail_table\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1254\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1252\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1253\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1254\u001b[0m     index, columns, col_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:227\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    225\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:394\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    383\u001b[0m             result[name] \u001b[38;5;241m=\u001b[39m array_type\u001b[38;5;241m.\u001b[39m_concat_same_type(\n\u001b[0;32m    384\u001b[0m                 arrs  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    385\u001b[0m             )\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;66;03m# Argument 1 to \"concatenate\" has incompatible type\u001b[39;00m\n\u001b[0;32m    388\u001b[0m             \u001b[38;5;66;03m# \"List[Union[ExtensionArray, ndarray[Any, Any]]]\"; expected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[38;5;66;03m# Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]],\u001b[39;00m\n\u001b[0;32m    393\u001b[0m             \u001b[38;5;66;03m# Sequence[Sequence[Sequence[Sequence[_SupportsArray[dtype[Any]]]]]]]\"\u001b[39;00m\n\u001b[1;32m--> 394\u001b[0m             result[name] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m warning_columns:\n\u001b[0;32m    397\u001b[0m     warning_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(warning_columns)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 168. MiB for an array with shape (21966856,) and data type int64"
     ]
    }
   ],
   "source": [
    "#Loading the availability table\n",
    "avail_table = pd.read_csv('final_avail_data.csv')\n",
    "avail_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397deb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the date col to a datetime col, and creating avail month col\n",
    "avail_table['date'] = pd.to_datetime(avail_table['date'])\n",
    "avail_table['avail_month'] = avail_table['date'].dt.month\n",
    "avail_table['avail_month'] = avail_table['avail_month'].astype(str)\n",
    "#print(avail_table.dtypes)\n",
    "#print(avail_table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ddea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing all columns which aren't listing_id, avail_month, and true_availability\n",
    "select_avail = avail_table.loc[:, ['listing_id','avail_month','true_availability']]\n",
    "select_avail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a9acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates from the table\n",
    "sel_avail_tf = select_avail.drop_duplicates()\n",
    "print(\"The original length of the table was\",len(select_avail),\"The new length of the table is\",len(sel_avail_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32ac1f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Combine the avail_month rows into a single col per listing id with comma separated values\n",
    "\n",
    "#Checking \"before\" view\n",
    "print(sel_avail_tf.loc[sel_avail_tf['listing_id'] ==29967])\n",
    "\n",
    "#Combining rows\n",
    "comb_avail = sel_avail_tf.groupby(['listing_id','true_availability'])['avail_month'].apply(','.join).reset_index()\n",
    "\n",
    "#Checking the \"after\"\n",
    "print(comb_avail.loc[comb_avail['listing_id'] == 29967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8856a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the unavailable listings\n",
    "is_avail = comb_avail.loc[comb_avail['true_availability']==True]\n",
    "#is_avail.true_availability.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ab6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the output\n",
    "is_avail.to_csv('available_listings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6b77f",
   "metadata": {},
   "source": [
    "### Joining the availability and review tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in table with 2 columns - listing_id and avail_month\n",
    "#listing_id is the primary key, avail month is a column containing a string with all the months of availability for the property \n",
    "#e.g., '1,2,3' for Jan, Feb, Mar.\n",
    "avail_table = is_avail.copy()\n",
    "#avail_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58bc5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Match the availability table to the review information table\n",
    "review_avail = pd.merge(final_reviews, avail_table, how = \"left\", on = \"listing_id\")\n",
    "#review_avail = review_avail.drop('Unnamed: 0', axis = 1)\n",
    "review_avail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd646e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that rows are updated correctly\n",
    "nan_listing_list = review_avail[review_avail['avail_month'].isna()]['listing_id'].values #210227\n",
    "print(\"There are\",len(nan_listing_list),\"listing ids which have null avail_month\")\n",
    "\n",
    "nan_avail_df = comb_avail.loc[comb_avail['listing_id'].isin(nan_listing_list)]\n",
    "print(\"They only have the value\",nan_avail_df.true_availability.unique(),\"for availability and were removed prior to the \\\n",
    "join with the reviews table\")\n",
    "\n",
    "#Find Nans\n",
    "#print(review_avail.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6852830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the null values in true availability and avail_month to zero\n",
    "review_avail['true_availability'] = review_avail['true_availability'].fillna(False)\n",
    "review_avail['avail_month'] = review_avail['avail_month'].fillna(0)\n",
    "\n",
    "#Find Nans\n",
    "#print(review_avail.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the availability in review month indicator column\n",
    "review_avail['avail_ind'] = review_avail.apply(lambda review_avail: str(review_avail.review_month) in str(review_avail.avail_month), axis = 1)\n",
    "review_avail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47afcc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Updates avail_ind from boolean to 1/0\n",
    "review_avail.loc[review_avail['avail_ind'] == True, 'avail_ind'] = 1\n",
    "review_avail.loc[review_avail['avail_ind'] == False, 'avail_ind'] = 0\n",
    "review_avail.loc[review_avail['listing_id']==29967]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying that everything with true availability == False has avail_ind == 0\n",
    "false_avail = review_avail.loc[review_avail['true_availability']== False]\n",
    "print(false_avail.avail_ind.unique())\n",
    "\n",
    "#Verifying that everything with avail_month == 0 has avail_ind == 0\n",
    "false_avail = review_avail.loc[review_avail['avail_month']== 0]\n",
    "print(false_avail.avail_ind.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a37eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the output data to csv\n",
    "review_avail.to_csv('q6a_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
